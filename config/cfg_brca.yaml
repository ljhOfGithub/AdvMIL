task: cont_gansurv # cont_gansurv
seed: 42
# cuda_id: 1
cuda_id: 0

# wandb_dir: /home/liup/repo/AdvMIL # path to this repo
# wandb_dir: /home/jupyter-ljh/data/mntdata/data0/LI_jihao/AdvMIL-BRCA # path to this repo 用于保存log和checkpoints的地方 放置了log-data_split_seed_0等，转移到了log_common中
# wandb_dir: /home/jupyter-ljh/data/mntdata/data0/LI_jihao/AdvMIL-BRCA/log_common # path to this repo 用于保存log和checkpoints的地方 上面写错了路径，导致可能混淆
wandb_dir: /home/jupyter-ljh/data/mntdata/data0/LI_jihao/AdvMIL-BRCA/log_test # path to this repo 用于保存log和checkpoints的地方 仅测试模式的
# wandb_dir: /home/jupyter-ljh/data/mydata/AdvMIL-main # path to this repo
# wandb_prj: AdvMIL-adv # wandb project name
# wandb_prj: AdvMIL-main # wandb project name 在网站上显示的项目名，不用预先建立
wandb_prj: AdvMIL-test # wandb project name 在网站上显示的项目名，不用预先建立 仅测试模式
# save_path: ./results-adv/nlst-patch # path to save log files during training and testing
# save_path: /home/jupyter-ljh/data/mntdata/data0/LI_jihao/AdvMIL-BRCA/log # path to save log files during training and testing
# save_path: /home/jupyter-ljh/data/mntdata/data0/LI_jihao/AdvMIL-BRCA/log_commmon # path to save log files during training and testing
save_path: /home/jupyter-ljh/data/mntdata/data0/LI_jihao/AdvMIL-BRCA/log_test # path to save log files during training and testing 仅测试模式的log

# data
# dataset: NLST
dataset: BRCA
# path_patch: /data/nlst/processed/feat-l1-RN50-B/pt_files # path to patch features, for patch-based models
# path_patch: /home/jupyter-ljh/data/mntdata/data0/LI_jihao/AdvMIL-BRCA/tiles-l2-s256-fea/pt_files # path to patch features, for patch-based models
# path_patch: /home/jupyter-ljh/data/mntdata/data0/LI_jihao/AdvMIL-BRCA/tiles-l1-s256-fea/pt_files # path to patch features, for patch-based models 好像只能用l1
path_patch: /home/jupyter-ljh/data/mntdata/data0/LI_jihao/AdvMIL-BRCA/tiles-l1-s256-fea/pt_files # path to patch features, for patch-based models 好像只能用l1
# path_graph: /data/nlst/processed/wsigraph-l1-features # path to WSI graphs, for graph-based models
path_graph: /data/nlst/processed/wsigraph-l1-features # path to WSI graphs, for graph-based models
path_cluster: /data/nlst/processed/patch-l1-cluster8-ids # path to patch clusters, for cluster-based models
path_coordx5: null
# path_label: ./table/nlst_path_full.csv # path to the csv table with patient_id, pathology_id, t, e
# path_label: /home/jupyter-ljh/data/mydata/DSCA-main/data_split/tcga_brca/tcga_brca_path_full_ljh.csv # path to the csv table with patient_id, pathology_id, t, e
path_label: /home/jupyter-ljh/data/mntdata/data0/LI_jihao/AdvMIL-BRCA/data_split/tcga_brca/tcga_brca_path_full_ljh.csv # path to the csv table with patient_id, pathology_id, t, e
feat_format: pt 
time_format: ratio
time_bins: 4
# data_split_path: ./data_split/nlst-fold{}.npz # path to data split
# data_split_path: /home/jupyter-ljh/data/mydata/DSCA-main/data_split/tcga_brca/tcga_brca-seed54-fold{}-ljh.npz # path to data split 使用DSCA所用的split
# data_split_path: /home/jupyter-ljh/data/mydata/DSCA-main/data_split/tcga_brca/tcga_brca-seed54-fold{}-ljh.npz # path to data split 使用DSCA所用的split
data_split_path: /home/jupyter-ljh/data/mntdata/data0/LI_jihao/AdvMIL-BRCA/data_split/tcga_brca/tcga_brca-seed54-fold{}-ljh.npz # path to data split 使用DSCA所用的split
data_split_seed: [0, 1, 2, 3, 4] # fold identifiers, used to fill the placeholder in `data_split_path`
# data_split_seed: 0 # fold identifiers, used to fill the placeholder in `data_split_path` 方便调试
save_prediction: True
train_sampling: null # w/o data sampling

# Backbone setting of MIL encoder
bcb_mode: patch # choose patch, cluster, or graph
bcb_dims: 1024-384-384 # the dims from input dim -> hidden dim -> embedding dim

# Generator setting (regarding the end part)
gen_dims: 384-1 # embedding dim -> out dim
gen_noi_noise: 0-1 # noise setting, 0-1 / 1-0 / 1-1
gen_noi_noise_dist: uniform  # noise type, gaussian / uniform
gen_noi_hops: 1
gen_norm: False
gen_dropout: 0.6
gen_out_scale: sigmoid

# Discriminator
disc_type: prj # how to fuse X and t: cat (vector concatenation) / prj (vector projection)
disc_netx_in_dim: 1024 # input dim of X
disc_netx_out_dim: 128 # out dim of X
disc_netx_ksize: 1
disc_netx_backbone: avgpool
disc_netx_dropout: 0.25
disc_nety_in_dim: 1 # input dim of t
disc_nety_hid_dims: 64-128 # hidden dim of t
disc_nety_norm: False
disc_nety_dropout: 0.0
disc_prj_path: x
disc_prj_iprd: instance # choose bag (regular projection) / instance (RLIP)

# loss for all
loss_gan_coef: 0.004  # coefficient of GANLoss
loss_netD: bce # choose bce / hinge / wasserstein 
loss_regl1_coef: 0.00001 # coefficient of L1 Regularization
# loss for discrete model
loss_mle_alpha: 0.0
# loss for continuous model
loss_recon_norm: l1 # l1/l2
loss_recon_alpha: 0.0
loss_recon_gamma: 0.0

# Optimizer
opt_netG: adam
opt_netG_lr: 0.00008 # learning rate of generator
opt_netG_weight_decay: 0.0005
opt_netD_lr: 0.00008 # learning rate of discriminator

#training
# epochs: 300 # epoch numbers
# epochs: 150 # epoch numbers 方便调试
epochs: 2 # epoch numbers 方便调试
batch_size: 1 
bp_every_batch: 16 #Backpropagation
# num_workers: 8 # work numbers for loading WSI features
num_workers: 0 # work numbers for loading WSI features
es_patience: 30 # es: early stopping
es_warmup: 5
es_verbose: True
es_start_epoch: 0
gen_updates: 1 # 1/2
monitor_metrics: loss # metrics on validation set for early stopping

# test
times_test_sample: 30 # sampling times when predicting survival from each WSI. 
log_plot: False

# only for semi-supervised training
semi_training: False
# semi_training: True
semi_training_mode: UD+LD # training mode: UD / LD / UD+LD / NA (see more in the line 735 of model_hanlder.py)
# ssl_epochs: 300 # epoch number of semi-supervised training
ssl_epochs: 2 # epoch number of semi-supervised training
ssl_num_labeled: 0.6 # the ratio of the labeled data split from the training data
ssl_kfold: 5 # the fold number for k-fold semi-supervised training 
ssl_resume_ckpt: best # won't be used
ssl_es_patience: 30 # early stopping setting
ssl_es_warmup: 5 # early stopping setting
ssl_es_verbose: True # if verbose when using early stopping
ssl_es_start_epoch: 0 # early stopping setting

# only for a testing mode
# test: False
test: True
test_wandb_prj: AdvMIL-best-zeromask-test # wandb project name of test mode
test_path: test # dataset name you want to test, which should be a key in the npz file for data split
# test_load_path: ./advmil_best_model/nlst-ablation_ncor_iprd_gl4-data_split_seed_{}-gen_noi_noise_0-1 # path to load trained models
test_load_path: /home/jupyter-ljh/data/mntdata/data0/LI_jihao/AdvMIL-BRCA/log_common/log-data_split_seed_{} # path to load trained models 加载已经训练好的模型
# test_save_path: ./results-robust/results-zeromask_test/advmil-best/nlst-test_maskzero_{}-data_split_seed_{} # path to save test results
test_save_path: /home/jupyter-ljh/data/mntdata/data0/LI_jihao/AdvMIL-BRCA/test/brca-test_maskzero_{}-data_split_seed_{} # path to save test results 保存测试结果
test_mask_ratio: 0.8 # mask ratio 
test_sampling_times: 1 # sampling times (in test mode) when predicting survival from each WSI. 
test_zero_noise: True # if using zero noise for testing
